{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2667c603",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "INPUTS = ['production/puri/tiles']\n",
    "OUTPUT = 'production/puri/modeloutput/footprints/'\n",
    "REGION = 'puri'\n",
    "MODELNAME = 'efficientnet-b6'\n",
    "CHECKPOINT = 'buildingsegmentation'\n",
    "IMAGESIZE = 512\n",
    "SCALES = [1, 3]\n",
    "DENSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ba55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba7aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask as buildingcrop\n",
    "from rasterio import features\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import shape, Polygon, Point\n",
    "from shapely.affinity import affine_transform\n",
    "\n",
    "from skimage import io\n",
    "from skimage import measure\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "sys.path.append('nn/')\n",
    "#from nbs.nn.unet import UNet\n",
    "from unet import UNet\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66aee04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ab8f6d-58d8-4d41-832c-57b3acd18741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1d65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = Path(INPUTS[0])\n",
    "OUTPUT = Path(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b76b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_tiles = INPUT\n",
    "tile_paths = [str(p) for p in region_tiles.glob('*') if 'tif' in str(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab126be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles to process 180\n"
     ]
    }
   ],
   "source": [
    "num_tiles = len(tile_paths)\n",
    "print(f'Number of tiles to process {num_tiles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f3b26",
   "metadata": {},
   "source": [
    "# 2.1 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d06800c-ef0d-4c05-bc19-656f6cd9872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME: 'efficientnet-b6'\n",
    "CHECKPOINT: 'checkpoints/buildingsegmentation'\n",
    "IMAGESIZE: 512\n",
    "SCALE: [1, 3]\n",
    "DENSE: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c07af36-791b-496c-804c-42e7a5534b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b839b2-1d76-47d6-b612-053552c64f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoints/buildingsegmentation'\n",
      "loaded checkpoint from 'buildingsegmentation' (epoch 92, best_score 80.36363636363636)\n"
     ]
    }
   ],
   "source": [
    "if num_tiles:\n",
    "    model = UNet(name=MODELNAME, pretrained=None)\n",
    "    #model = nn.DataParallel(model)\n",
    "    \n",
    "    # if torch.cuda.is_available():\n",
    "    #     model = model.cuda()\n",
    "    # else:\n",
    "    #     model = model.to('cpu')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #checkpoint_path = Path(Model.get_model_path(CHECKPOINT, version=1))\n",
    "    checkpoint_path = Path('checkpoints/buildingsegmentation')\n",
    "    if checkpoint_path.exists():\n",
    "        print(\"=> loading checkpoint '{}'\".format(str(checkpoint_path)))\n",
    "        checkpoint = torch.load(str(checkpoint_path), map_location='cpu')\n",
    "        loaded_dict = checkpoint['state_dict']\n",
    "        sd = model.state_dict()\n",
    "        for k in model.state_dict():\n",
    "            if k in loaded_dict:\n",
    "                sd[k] = loaded_dict[k]\n",
    "        \n",
    "        loaded_dict = sd\n",
    "        model.load_state_dict(loaded_dict)\n",
    "        best_score = checkpoint['best_score']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(\"loaded checkpoint from '{}' (epoch {}, best_score {})\"\n",
    "                .format(CHECKPOINT, checkpoint['epoch'], checkpoint['best_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81802b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if num_tiles:\n",
    "#     model = UNet(name=MODELNAME, pretrained=None)\n",
    "#     model = nn.DataParallel(model)\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         model = model.cuda()\n",
    "\n",
    "    \n",
    "#     #checkpoint_path = Path(Model.get_model_path(CHECKPOINT, version=1))\n",
    "#     checkpoint_path = Path('checkpoints/buildingsegmentation')\n",
    "#     if checkpoint_path.exists():\n",
    "#         print(\"=> loading checkpoint '{}'\".format(str(checkpoint_path)))\n",
    "#         checkpoint = torch.load(str(checkpoint_path), map_location='cpu')\n",
    "#         loaded_dict = checkpoint['state_dict']\n",
    "#         sd = model.state_dict()\n",
    "#         for k in model.state_dict():\n",
    "#             if k in loaded_dict:\n",
    "#                 sd[k] = loaded_dict[k]\n",
    "        \n",
    "#         loaded_dict = sd\n",
    "#         model.load_state_dict(loaded_dict)\n",
    "#         best_score = checkpoint['best_score']\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         print(\"loaded checkpoint from '{}' (epoch {}, best_score {})\"\n",
    "#                 .format(CHECKPOINT, checkpoint['epoch'], checkpoint['best_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a24e37",
   "metadata": {},
   "source": [
    "# 2.2 Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = [] #footprints geometry\n",
    "values = [] #pixel values\n",
    "footprints_per_scale = {} #this is to store the lower scale footprints anf check if it intersects with higher scale\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca130c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on 180\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(f'Running prediction on {num_tiles}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15119da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coords(polygon, transform):\n",
    "    return affine_transform(polygon, [transform.a, transform.b, \n",
    "                                      transform.d, transform.e, \n",
    "                                      transform.xoff, transform.yoff])\n",
    "\n",
    "def check_intersection(base, polygon):\n",
    "    intersection = base.intersects(polygon)\n",
    "    return intersection.any()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86744fdb-30e2-4b8b-9a0e-f12794741db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743028c1-4e8c-41fe-9f33-a972e45011ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 180/180 [10:06<00:00,  3.37s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 180/180 [1:42:41<00:00, 34.23s/it]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for SCALE in SCALES:\n",
    "    for index in tqdm(range(num_tiles)):\n",
    "        try:\n",
    "            tile_path = tile_paths[index]\n",
    "            tile_name = tile_path.split('/')[-1]\n",
    "\n",
    "            with rio.open(tile_path, 'r') as ref:\n",
    "                transform = ref.transform\n",
    "                crs = ref.crs\n",
    "\n",
    "                #read tile data\n",
    "                data = ref.read()\n",
    "                ref.close()\n",
    "                data = np.transpose(data, (1, 2, 0))\n",
    "                \n",
    "                if DENSE:\n",
    "                    data = data * 1.5\n",
    "                \n",
    "                h, w = (np.asarray(data.shape[:2]) * SCALE).astype('int32')\n",
    "                scaled_image = cv2.resize(data, (w, h) , interpolation=cv2.INTER_NEAREST)\n",
    "                scaled_mask = np.zeros((h, w, 3)).copy()\n",
    "                for it in range(SCALE):\n",
    "                    for jt in range(SCALE):\n",
    "                        x = it * IMAGESIZE\n",
    "                        y = jt * IMAGESIZE\n",
    "\n",
    "                        image = scaled_image[y : y + IMAGESIZE, x : x + IMAGESIZE, :]\n",
    "                        image = np.asarray(image, dtype='float32') / 255\n",
    "                        for i in range(3):\n",
    "                            image[..., i] = (image[..., i] - mean[i]) / std[i]\n",
    "\n",
    "                        image = torch.from_numpy(image.transpose((2, 0, 1)).copy()).float()\n",
    "                        image = image.unsqueeze(0)\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            #pdb.set_trace()\n",
    "                            pred = model(image.to(device))\n",
    "                            out = torch.sigmoid(pred).to(device).numpy()\n",
    "                            out = out[0, ...]\n",
    "                            out = np.transpose(out, (1, 2, 0))\n",
    "                            scaled_mask[y : y + IMAGESIZE, x : x + IMAGESIZE, ...] = out\n",
    "\n",
    "                mask = cv2.resize(scaled_mask, (IMAGESIZE, IMAGESIZE), interpolation=cv2.INTER_NEAREST)\n",
    "                mask = mask[..., 2] * (1 -  mask[..., 1]) * (1 - mask[..., 0]) #subtract boundary and contact point\n",
    "                \n",
    "                #watershed method to seperate buildings\n",
    "                mask0 = (mask > 0.6)\n",
    "                local_maxi = peak_local_max(mask, indices=False, footprint=np.ones((11, 11)), \n",
    "                                                   labels=(mask > 0.4))\n",
    "                local_maxi[mask0] = True\n",
    "                seed_msk = ndi.label(local_maxi)[0]\n",
    "                y_pred = watershed(-mask, seed_msk, mask=(mask > 0.4), watershed_line=True)\n",
    "                y_pred = measure.label(y_pred, connectivity=2, background=0).astype('uint8')\n",
    "\n",
    "                #generate polygons from the predictions\n",
    "                polygon_generator = features.shapes(y_pred, mask=y_pred > 0)\n",
    "                for polygon, value in polygon_generator:\n",
    "                    poly = shape(polygon).buffer(0.0)\n",
    "                    if poly.area > 5:\n",
    "                        ############################################################################\n",
    "                        #This entire logic is written because model does not do great job at scale 1 \n",
    "                        #when image resolution is not good and there is high building density \n",
    "                        #so at scale the generate result will be considered when scale 1 fails to detect the buildinf\n",
    "                        ############################################################################\n",
    "                        #for first scale directly add the polygons\n",
    "                        if SCALE != SCALES[-1]:\n",
    "                            polygons.append(transform_coords(poly, transform))\n",
    "                            values.append(value) \n",
    "                        else:\n",
    "                            # check if building not detected already\n",
    "                            base = footprints_per_scale[SCALES[0]]['geometry'] #this is footprints generated at first scale\n",
    "                            if not check_intersection(base, poly):\n",
    "                                polygons.append(transform_coords(poly, transform))\n",
    "                                values.append(value)\n",
    "\n",
    "                                                                                           \n",
    "            footprints_per_scale[SCALE] = gpd.GeoDataFrame({'geometry': polygons})\n",
    "        except Exception as e:\n",
    "            print(e, index)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4f561",
   "metadata": {},
   "source": [
    "# 2.3 Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8d96d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(str(OUTPUT), exist_ok=True)\n",
    "if num_buildings:\n",
    "    output_file = f'{str(OUTPUT)}/{REGION}_footprints_from_model.geojson'\n",
    "    print(f'Writing output to {output_file}')\n",
    "    polygon_gdf = gpd.GeoDataFrame({'geometry': polygons, 'value': values}, \n",
    "                                        crs=crs.to_wkt())\n",
    "    polygon_gdf.to_file(f'{output_file}', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be41b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
